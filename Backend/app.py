from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import json
import re
import string
import math
import time
from collections import defaultdict
import joblib
import nltk
from nltk.corpus import stopwords


app = Flask(__name__)
CORS(app)

# Chemins des fichiers
BASE_FOLDER = os.path.dirname(os.path.abspath(__file__))
MODEL_FOLDER = os.path.join(BASE_FOLDER, "../ri_model")  
DOCS_FOLDER = os.path.join(BASE_FOLDER, "../med_md")
MEDICAMENTS_JSON_PATH = os.path.join(BASE_FOLDER, "../meta_data.json")

# TÃ©lÃ©charger les ressources NLTK
try:
    nltk.data.find("tokenizers/punkt")
except:
    nltk.download("punkt")
try:
    nltk.data.find("corpora/stopwords")
except:
    nltk.download("stopwords")

french_stopwords = set(stopwords.words("french"))

# âœ… AJOUT : Afficher les stopwords pour vÃ©rification
print(f"ğŸ“‹ Nombre de stopwords franÃ§ais chargÃ©s: {len(french_stopwords)}")
print(f"ğŸ“‹ Exemples de stopwords: {list(french_stopwords)[:20]}")

# Variables globales
inverted_index = {}
idf = {}
tfidf_vectors = {}
documents = {}
medicaments_data = []
medicaments_by_id = {}


def clean_text(text: str) -> str:
    """Nettoie le texte : minuscules, suppression ponctuation"""
    text = text.lower()
    text = re.sub(r"[{}]".format(re.escape(string.punctuation)), " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text


def load_documents(folder: str) -> dict:
    """Charge les documents .md"""
    docs = {}
    if os.path.exists(folder):
        for f in sorted(os.listdir(folder)):
            if f.endswith(".md"):
                with open(os.path.join(folder, f), "r", encoding="utf-8") as file:
                    docs[f] = file.read()
    return docs


def load_medicaments_data(json_path: str) -> list:
    """Charge les donnÃ©es des mÃ©dicaments depuis le JSON"""
    if os.path.exists(json_path):
        with open(json_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []


def initialize_search_engine():
    """Initialise le moteur de recherche avec le modÃ¨le sauvegardÃ©"""
    global inverted_index, idf, tfidf_vectors, documents, medicaments_data, medicaments_by_id
    
    print("ğŸ”„ Initialisation du moteur de recherche...")
    
    # âœ… CHARGER LE MODÃˆLE DEPUIS LES FICHIERS .PKL
    tfidf_path = os.path.join(MODEL_FOLDER, "tfidf_vectors.pkl")
    idf_path = os.path.join(MODEL_FOLDER, "idf.pkl")
    index_path = os.path.join(MODEL_FOLDER, "inverted_index.pkl")
    
    if os.path.exists(tfidf_path) and os.path.exists(idf_path) and os.path.exists(index_path):
        print("ğŸ“¦ Chargement du modÃ¨le sauvegardÃ©...")
        tfidf_vectors = joblib.load(tfidf_path)
        idf = joblib.load(idf_path)
        inverted_index = joblib.load(index_path)
        print(f"âœ… ModÃ¨le chargÃ© depuis {MODEL_FOLDER}")
        print(f"   - {len(tfidf_vectors)} vecteurs TF-IDF")
        print(f"   - {len(idf)} termes IDF")
        print(f"   - {len(inverted_index)} termes dans l'index")
    else:
        print("âš ï¸  Fichiers .pkl non trouvÃ©s, impossible de charger le modÃ¨le")
        print(f"   VÃ©rifiez que ces fichiers existent :")
        print(f"   - {tfidf_path}")
        print(f"   - {idf_path}")
        print(f"   - {index_path}")
        return False
    
    # Charger les documents (pour les snippets)
    documents = load_documents(DOCS_FOLDER)
    print(f"âœ… Documents chargÃ©s : {len(documents)}")
    
    # Charger les donnÃ©es des mÃ©dicaments
    medicaments_data = load_medicaments_data(MEDICAMENTS_JSON_PATH)
    print(f"âœ… DonnÃ©es mÃ©dicaments chargÃ©es : {len(medicaments_data)}")
    
    # CrÃ©er un mapping id -> medicament
    for med in medicaments_data:
        med_id = med.get('id')
        if med_id:
            medicaments_by_id[str(med_id)] = med
    
    print("âœ… Moteur de recherche initialisÃ©\n")
    return True


def cosine_similarity_dict(v1, v2):
    """Calcule la similaritÃ© cosinus entre deux vecteurs (dictionnaires)"""
    common = set(v1.keys()) & set(v2.keys())
    if not common:
        return 0.0
    
    num = sum(v1[t] * v2[t] for t in common)
    denom1 = math.sqrt(sum(v**2 for v in v1.values()))
    denom2 = math.sqrt(sum(v**2 for v in v2.values()))
    
    if denom1 == 0 or denom2 == 0:
        return 0.0
    
    return num / (denom1 * denom2)


def build_query_vector(query: str) -> dict:
    """Construit le vecteur TF-IDF de la requÃªte"""
    query = clean_text(query)
    tokens = [t for t in query.split() if t and t not in french_stopwords]
    
    # âœ… AJOUT : Log pour debugging
    print(f"ğŸ” RequÃªte nettoyÃ©e: '{query}'")
    print(f"ğŸ” Tokens aprÃ¨s stopwords: {tokens}")
    
    # Calculer TF pour la requÃªte
    tf_query = defaultdict(int)
    for t in tokens:
        tf_query[t] += 1
    
    # Construire le vecteur TF-IDF
    q_vec = {}
    for term, tf in tf_query.items():
        if term in idf:
            q_vec[term] = tf * idf[term]
        else:
            print(f"âš ï¸  Terme '{term}' absent de l'index IDF")
    
    print(f"âœ… Vecteur requÃªte: {len(q_vec)} termes")
    return q_vec


def extract_id_from_filename(filename: str) -> str:
    """Extrait l'ID du nom de fichier (ex: '1.md' -> '1')"""
    return filename.replace('.md', '')


def search_engine(query: str, top_k: int = 10, min_score: float = 0.0):
    """Effectue la recherche - comportement identique au modÃ¨le Colab"""
    start_time = time.time()
    
    # Construire le vecteur de la requÃªte
    q_vec = build_query_vector(query)
    if not q_vec:
        return [], 0
    
    # Calculer les scores de similaritÃ© pour TOUS les documents
    scores = {}
    for doc_id, d_vec in tfidf_vectors.items():
        score = cosine_similarity_dict(q_vec, d_vec)
        # âœ… Pas de filtrage par min_score, comme dans Colab
        scores[doc_id] = score
    
    # Trier par score dÃ©croissant
    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    
    # âœ… MODIFICATION PRINCIPALE : Prendre exactement top_k documents
    # Sans dÃ©duplication complexe, juste les top_k premiers
    top_docs = ranked[:top_k]
    
    # Construire les rÃ©sultats
    results = []
    
    for doc_id, score in top_docs:
        # âœ… RÃ©cupÃ©rer les infos sans filtrage supplÃ©mentaire
        med_id = extract_id_from_filename(doc_id)
        med_info = medicaments_by_id.get(med_id)
        
        # PrÃ©parer le rÃ©sultat mÃªme si certaines infos manquent
        nom = med_info.get("nom", "MÃ©dicament inconnu") if med_info else "MÃ©dicament inconnu"
        snippet = med_info.get("snippet", "Aucune description disponible.") if med_info else "Aucune description disponible."
        url = med_info.get("url", "#") if med_info else "#"
        image_url = med_info.get("image_url", "") if med_info else ""
        
        result = {
            "doc_id": doc_id,
            "id": med_id,
            "score": round(score, 4),
            "snippet": snippet,
            "nom": nom,
            "url": url,
            "image_url": image_url
        }
        results.append(result)
    
    search_time = time.time() - start_time
    
    # âœ… Log pour debugging
    print(f"ğŸ” Query: '{query}' â†’ {len(results)} rÃ©sultats")
    print(f"   Top 5: {[r['doc_id'] for r in results[:5]]}")
    
    return results, search_time


# ==================== ROUTES API ====================

@app.route('/')
def home():
    """Page d'accueil de l'API"""
    return jsonify({
        "message": "API MediSearch - SystÃ¨me de Recherche d'Information",
        "status": "running",
        "version": "2.0.0",
        "model": "TF-IDF avec modÃ¨le sauvegardÃ©",
        "endpoints": {
            "/api/search": "POST - Rechercher des mÃ©dicaments",
            "/api/stats": "GET - Statistiques du systÃ¨me",
            "/api/medicaments": "GET - Liste de tous les mÃ©dicaments"
        }
    })


@app.route('/api/search', methods=['POST', 'OPTIONS'])
def search():
    """Endpoint de recherche"""
    if request.method == 'OPTIONS':
        return '', 204
    
    try:
        data = request.get_json()
        query = data.get('query', '')
        top_k = data.get('top_k', 10)
        
        if not query:
            return jsonify({"error": "Query parameter is required"}), 400
        
        results, search_time = search_engine(query, top_k)
        
        return jsonify({
            "query": query,
            "results": results,
            "total_results": len(results),
            "search_time": round(search_time, 3)
        })
    
    except Exception as e:
        print(f"âŒ Erreur de recherche: {str(e)}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/stats', methods=['GET'])
def stats():
    """Retourne les statistiques du systÃ¨me"""
    return jsonify({
        "total_terms": len(inverted_index),
        "total_documents": len(tfidf_vectors),
        "total_medicaments": len(medicaments_data),
        "indexed_medicaments": len(medicaments_by_id),
        "model_loaded": len(tfidf_vectors) > 0,
        "status": "operational"
    })


@app.route('/api/medicaments', methods=['GET'])
def get_medicaments():
    """Retourne la liste de tous les mÃ©dicaments"""
    return jsonify({
        "medicaments": medicaments_data,
        "total": len(medicaments_data)
    })


# ==================== POINT D'ENTRÃ‰E ====================

if __name__ == '__main__':
    # Initialiser le moteur de recherche
    success = initialize_search_engine()
    
    if not success:
        print("âŒ Ã‰chec de l'initialisation du moteur de recherche")
        print("   VÃ©rifiez que le dossier ri_model contient les fichiers .pkl")
        exit(1)
    
    # DÃ©marrer le serveur Flask
    print("=" * 60)
    print("âœ… Serveur Flask dÃ©marrÃ©")
    print(f"   ğŸŒ http://localhost:5000")
    print(f"   ğŸŒ http://127.0.0.1:5000")
    print(f"ğŸ“Š {len(medicaments_data)} mÃ©dicaments chargÃ©s")
    print(f"ğŸ“š {len(tfidf_vectors)} documents indexÃ©s")
    print(f"ğŸ” {len(inverted_index)} termes dans l'index")
    print("=" * 60 + "\n")
    
    app.run(host='0.0.0.0', port=5000, debug=True, use_reloader=False)